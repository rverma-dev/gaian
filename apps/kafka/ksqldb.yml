apiVersion: v1
kind: ConfigMap
metadata:
  name: openmeter-ksql-server-jmx-configmap
  labels:
    app: ksql-server
data:
  ksql-metrics-config.yml: |+
    jmxUrl: service:jmx:rmi:///jndi/rmi://localhost:5555/jmxrmi
    lowercaseOutputName: true
    lowercaseOutputLabelNames: true
    whitelistObjectNames:
      - 'io.confluent.ksql.metrics:*'
      # The two lines below are used to pull the Kafka Client Producer & consumer metrics from KSQL Client.
      # If you care about Producer/Consumer metrics for KSQL, please uncomment 2 lines below.
      # Please note that this increases the scrape duration to about 1 second as it needs to parse a lot of data.
      - 'kafka.consumer:*'
      - 'kafka.producer:*'
      - 'kafka.streams:*'
    blacklistObjectNames:
      - kafka.streams:type=kafka-metrics-count
      # This will ignore the admin client metrics from KSQL server and will blacklist certain metrics
      # that do not make sense for ingestion.
      - 'kafka.admin.client:*'
      - 'kafka.consumer:type=*,id=*'
      - 'kafka.consumer:type=*,client-id=*'
      - 'kafka.consumer:type=*,client-id=*,node-id=*'
      - 'kafka.producer:type=*,id=*'
      - 'kafka.producer:type=*,client-id=*'
      - 'kafka.producer:type=*,client-id=*,node-id=*'
      - 'kafka.streams:type=stream-processor-node-metrics,thread-id=*,task-id=*,processor-node-id=*'
      - 'kafka.*:type=kafka-metrics-count,*'
    rules:
      # "io.confluent.ksql.metrics:type=producer-metrics,key=*,id=*"
      # "io.confluent.ksql.metrics:type=consumer-metrics,key=*,id=*"
      - pattern: io.confluent.ksql.metrics<type=(.+), key=(.+), id=(.+)><>([^:]+)
        name: ksql_$1_$4
        labels:
          key: '$2'
          id: '$3'
      # "io.confluent.ksql.metrics:type=_confluent-ksql-<cluster-id>ksql-engine-query-stats"
      # The below statement parses KSQL Cluster Name and adds a new label so that per cluster data is searchable.
      - pattern: io.confluent.ksql.metrics<type=_confluent-ksql-(.+)ksql-engine-query-stats><>([^:]+)
        name: 'ksql_ksql_engine_query_stats_$2'
        labels:
          ksql_cluster: $1
      # "io.confluent.ksql.metrics:type=ksql-queries,status=_confluent-ksql-<cluser-id>_query_<query>
      # The below statement parses KSQL query specific status
      - pattern: 'io.confluent.ksql.metrics<type=(.+), status=_confluent-ksql-(.+)query_(.+)><>(.+): (.+)'
        value: 1
        name: ksql_ksql_metrics_$1_$4
        labels:
          ksql_query: $3
          ksql_cluster: $2
          $4: $5
      # kafka.streams:type=stream-processor-node-metrics,processor-node-id=*,task-id=*,thread-id=*
      # kafka.streams:type=stream-record-cache-metrics,record-cache-id=*,task-id=*,thread-id=*
      # kafka.streams:type=stream-state-metrics,rocksdb-state-id=*,task-id=*,thread-id=*
      # kafka.streams:type=stream-state-metrics,rocksdb-state-id=*,task-id=*,thread-id=*
      - pattern: 'kafka.streams<type=(.+), thread-id=(.+), task-id=(.+), (.+)=(.+)><>(.+):'
        name: kafka_streams_$1_$6
        type: GAUGE
        labels:
          thread_id: '$2'
          task_id: '$3'
          $4: '$5'
      # kafka.streams:type=stream-task-metrics,task-id=*,thread-id=*
      - pattern: 'kafka.streams<type=(.+), thread-id=(.+), task-id=(.+)><>(.+):'
        name: kafka_streams_$1_$4
        type: GAUGE
        labels:
          thread_id: '$2'
          task_id: '$3'
      # kafka.streams:type=stream-metrics,client-id=*
      - pattern: 'kafka.streams<type=stream-metrics, (.+)=(.+)><>(state|alive-stream-threads|commit-id|version|application-id): (.+)'
        name: kafka_streams_stream_metrics
        value: 1
        type: UNTYPED
        labels:
          $1: '$2'
          $3: '$4'
      # kafka.streams:type=stream-thread-metrics,thread-id=*
      - pattern: 'kafka.streams<type=(.+), (.+)=(.+)><>([^:]+)'
        name: kafka_streams_$1_$4
        type: GAUGE
        labels:
          $2: '$3'
      # "kafka.consumer:type=app-info,client-id=*"
      # "kafka.producer:type=app-info,client-id=*"
      - pattern: 'kafka.(.+)<type=app-info, client-id=(.+)><>(.+): (.+)'
        value: 1
        name: kafka_$1_app_info
        labels:
          client_type: $1
          client_id: $2
          $3: $4
        type: UNTYPED
      # "kafka.consumer:type=consumer-metrics,client-id=*, protocol=*, cipher=*"
      # "kafka.consumer:type=type=consumer-fetch-manager-metrics,client-id=*, topic=*, partition=*"
      # "kafka.producer:type=producer-metrics,client-id=*, protocol=*, cipher=*"
      - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+), (.+)=(.+)><>(.+):'
        name: kafka_$1_$2_$9
        type: GAUGE
        labels:
          client_type: $1
          $3: '$4'
          $5: '$6'
          $7: '$8'
      # "kafka.consumer:type=consumer-node-metrics,client-id=*, node-id=*"
      # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*, topic=*"
      # "kafka.producer:type=producer-node-metrics,client-id=*, node-id=*"
      # "kafka.producer:type=producer-topic-metrics,client-id=*, topic=*"
      - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+), (.+)=(.+)><>(.+):'
        name: kafka_$1_$2_$7
        type: GAUGE
        labels:
          client_type: $1
          $3: '$4'
          $5: '$6'
      # "kafka.consumer:type=consumer-fetch-manager-metrics,client-id=*"
      # "kafka.consumer:type=consumer-metrics,client-id=*"
      # "kafka.producer:type=producer-metrics,client-id=*"
      - pattern: 'kafka.(.+)<type=(.+), (.+)=(.+)><>(.+):'
        name: kafka_$1_$2_$5
        type: GAUGE
        labels:
          client_type: $1
          $3: '$4'
      - pattern: 'kafka.(.+)<type=(.+)><>(.+):'
        name: kafka_$1_$2_$3
        labels:
          client_type: $1

# ---
# apiVersion: v1
# kind: ConfigMap
# metadata:
#   name: ksql-queries-configmap
#   labels:
#     app: ksql-server
# data:
#   queries.sql: |-
#     -- From http://docs.confluent.io/current/ksql/docs/tutorials/basics-docker.html#create-a-stream-and-table
    
#     -- Create a stream pageviews_original from the Kafka topic pageviews, specifying the value_format of DELIMITED
#     CREATE STREAM pageviews_original (viewtime bigint, userid varchar, pageid varchar) WITH (kafka_topic='pageviews', value_format='DELIMITED');
    
#     -- Create a table users_original from the Kafka topic users, specifying the value_format of JSON
#     CREATE TABLE users_original (registertime BIGINT, gender VARCHAR, regionid VARCHAR, userid VARCHAR) WITH (kafka_topic='users', value_format='JSON', key = 'userid');
    
#     -- Create a persistent query by using the CREATE STREAM keywords to precede the SELECT statement
#     CREATE STREAM pageviews_enriched AS SELECT users_original.userid AS userid, pageid, regionid, gender FROM pageviews_original LEFT JOIN users_original ON pageviews_original.userid = users_original.userid;
    
#     -- Create a new persistent query where a condition limits the streams content, using WHERE
#     CREATE STREAM pageviews_female AS SELECT * FROM pageviews_enriched WHERE gender = 'FEMALE';
    
#     -- Create a new persistent query where another condition is met, using LIKE
#     CREATE STREAM pageviews_female_like_89 WITH (kafka_topic='pageviews_enriched_r8_r9') AS SELECT * FROM pageviews_female WHERE regionid LIKE '%_8' OR regionid LIKE '%_9';
    
#     -- Create a new persistent query that counts the pageviews for each region and gender combination in a tumbling window of 30 seconds when the count is greater than one
#     CREATE TABLE pageviews_regions WITH (VALUE_FORMAT='avro') AS SELECT gender, regionid , COUNT(*) AS numusers FROM pageviews_enriched WINDOW TUMBLING (size 30 second) GROUP BY gender, regionid HAVING COUNT(*) > 1;
---
apiVersion: v1
kind: Service
metadata:
  name: openmeter-ksql-server
  labels:
    app: ksql-server
spec:
  ports:
      - name: ksql-server
        port: 8088
      - name: metrics
        port: 5556
  selector:
    app: ksql-server
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: openmeter-ksql-server
  labels:
    app: ksql-server
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ksql-server
  template:
    metadata:
      labels:
        app: ksql-server
    spec:
      containers:
        - name: prometheus-jmx-exporter
          image: "bitnami/jmx-exporter:latest"
          imagePullPolicy: "IfNotPresent"
          args:
          - "5556"
          - /etc/jmx-ksql-server/ksql-metrics-config.yml
          ports:
          - containerPort: 5556
            name: tcp-prometheus
          resources:
            limits:
              cpu: 200m
              memory: 400Mi
          volumeMounts:
          - name: jmx-config
            mountPath: /etc/jmx-ksql-server
        - name: ksql-server
          image: bitnami/ksql:7.3.7
          imagePullPolicy: "IfNotPresent"
          ports:
            - name: server
              containerPort: 8088
              protocol: TCP
            - containerPort: 5555
              name: jmx
          resources:
            limits:
              cpu: 200m
              memory: 2Gi
            requests:
              cpu: 200m
              memory: 2Gi
          env:
          - name: KSQL_BOOTSTRAP_SERVERS
            value: PLAINTEXT://openmeter-kafka-bootstrap:9092
          - name: KSQL_KSQL_SERVICE_ID
            value: ksqldb
          - name: KSQL_LISTENERS
            value: http://0.0.0.0:8088
          - name: KSQL_KSQL_LOGGING_PROCESSING_STREAM_AUTO_CREATE
            value: "true"
          - name: KSQL_KSQL_LOGGING_PROCESSING_TOPIC_AUTO_CREATE
            value: "true"            
          - name: JMX_PORT
            value: "5555"
          - name: KSQL_JVM_PERFORMANCE_OPTS
            value: "-Dcom.sun.management.jmxremote -Dcom.sun.management.jmxremote.port=5555 -Dcom.sun.management.jmxremote.rmi.port=5555 -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Djava.rmi.server.hostname=localhost"

      volumes:
      - name: jmx-config
        configMap:
          name: openmeter-ksql-server-jmx-configmap
---
